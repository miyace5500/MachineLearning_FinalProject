# -*- coding: utf-8 -*-
"""MachineLearning_FinalProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aZrSvAm1G0HpIAxnE-3llDwSI6KnnkeO
"""

# ğŸ“Œ å¥—ä»¶åŒ¯å…¥
import pandas as pd
import os

# ğŸ“Œ è®€å– CSV è³‡æ–™
df = pd.read_csv("/content/test.csv", nrows=5000)  # ç‚ºæ¸¬è©¦å¯å…ˆè®€å–å‰ 5000 ç­†
print("è³‡æ–™è®€å–å®Œæˆï¼Œå‰äº”ç­†è³‡æ–™ï¼š")
print(df.head())

# ğŸ“Œ è½‰æ›æ™‚é–“æ¬„ä½ç‚º datetime å‹åˆ¥
df['time'] = pd.to_datetime(df['time'])
print("\næ™‚é–“æ¬„ä½è½‰æ›å®Œæˆï¼š")
print(df['time'].dtypes)

# ğŸ“Œ è³‡æ–™æ¦‚è¦½
print("\nè³‡æ–™é›†è³‡è¨Šï¼š")
print(df.info())
print("\næ¬„ä½çµ±è¨ˆæè¿°ï¼š")
print(df.describe(include='all'))

# ===============================
# 1ï¸âƒ£ æ•™å¸«å¼å­¸ç¿’ç”¨ï¼šä¾ enroll_id èšåˆç‰¹å¾µ
# ===============================
# æ¯å€‹å­¸ç¿’è€…çš„ç¸½è¡Œç‚ºæ•¸ã€å”¯ä¸€è¡Œç‚ºç¨®é¡ã€äº’å‹•æœƒè©±æ•¸ã€æ´»å‹•æ™‚é–“è·¨åº¦
agg_supervised = df.groupby('enroll_id').agg(
    total_actions=('action', 'count'),  # ç¸½è¡Œç‚ºæ•¸
    unique_actions=('action', pd.Series.nunique),  # ä¸åŒçš„è¡Œç‚ºç¨®é¡æ•¸
    session_count=('session_id', pd.Series.nunique),  # äº’å‹•æœƒè©±æ•¸
    first_activity=('time', 'min'),  # æœ€æ—©æ´»å‹•æ™‚é–“
    last_activity=('time', 'max')    # æœ€æ™šæ´»å‹•æ™‚é–“
).reset_index()

# è¨ˆç®—æ´»å‹•å¤©æ•¸è·¨åº¦
agg_supervised['activity_span_days'] = (agg_supervised['last_activity'] - agg_supervised['first_activity']).dt.days

# åˆªé™¤æš«æ™‚ä¸éœ€è¦çš„æ¬„ä½
agg_supervised.drop(columns=['first_activity', 'last_activity'], inplace=True)

# æ–°å¢é€€èª²æ¨™ç±¤ï¼ˆtruthï¼‰
agg_supervised['dropout'] = df.groupby('enroll_id')['truth'].first().values

print("æ•™å¸«å¼å­¸ç¿’ç‰¹å¾µèšåˆå®Œæˆï¼š")
print(agg_supervised.head())

# ===============================
# ğŸ“Œ 1ï¸âƒ£ æ•™å¸«å¼å­¸ç¿’æ¨¡å‹è¨“ç·´ï¼ˆé€€èª²é æ¸¬ï¼‰
# ===============================
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# ç‰¹å¾µèˆ‡æ¨™ç±¤
features = ['unique_actions', 'session_count', 'activity_span_days']
X = agg_supervised[features]
y = agg_supervised['dropout']

# åˆ‡åˆ†è¨“ç·´é›†èˆ‡æ¸¬è©¦é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# -------------------------------
# (A) é‚è¼¯æ–¯è¿´æ­¸æ¨¡å‹
# -------------------------------
log_model = LogisticRegression(max_iter=1000, class_weight='balanced')
log_model.fit(X_train, y_train)
y_pred_log = log_model.predict(X_test)

print("ğŸ“Œ Logistic Regression Classification Report:")
print(classification_report(y_test, y_pred_log))

# æ··æ·†çŸ©é™£
conf_matrix_log = confusion_matrix(y_test, y_pred_log)
plt.figure(figsize=(6,4))
sns.heatmap(conf_matrix_log, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Retained','Dropped'], yticklabels=['Retained','Dropped'])
plt.title("Logistic Regression Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# -------------------------------
# (B) æ±ºç­–æ¨¹æ¨¡å‹
# -------------------------------
tree_model = DecisionTreeClassifier(max_depth=4, random_state=42)
tree_model.fit(X_train, y_train)
y_pred_tree = tree_model.predict(X_test)

print("ğŸ“Œ Decision Tree Classification Report:")
print(classification_report(y_test, y_pred_tree))

plt.figure(figsize=(14,8))
plot_tree(tree_model, feature_names=features, class_names=['Retained','Dropped'],
          filled=True, rounded=True)
plt.title("Decision Tree Visualization")
plt.show()

# ===============================
# 2ï¸âƒ£ éæ•™å¸«å¼å­¸ç¿’ç”¨ï¼šè¡Œç‚ºèšåˆä¾›åˆ†ç¾¤åˆ†æ
# ===============================
# èšåˆç‰¹å¾µå¯ä»¥èˆ‡æ•™å¸«å¼ç›¸åŒï¼Œä½†ä¸åŒ…å«æ¨™ç±¤
agg_unsupervised = df.groupby('enroll_id').agg(
    total_actions=('action', 'count'),
    unique_actions=('action', pd.Series.nunique),
    session_count=('session_id', pd.Series.nunique),
    first_activity=('time', 'min'),
    last_activity=('time', 'max')
).reset_index()

agg_unsupervised['activity_span_days'] = (agg_unsupervised['last_activity'] - agg_unsupervised['first_activity']).dt.days
agg_unsupervised.drop(columns=['first_activity', 'last_activity'], inplace=True)

print("éæ•™å¸«å¼å­¸ç¿’ç‰¹å¾µèšåˆå®Œæˆï¼š")
print(agg_unsupervised.head())

# ===============================
# ğŸ“Œ 2ï¸âƒ£ éæ•™å¸«å¼å­¸ç¿’ï¼ˆKMeans åˆ†ç¾¤ï¼‰
# ===============================
from sklearn.cluster import KMeans

# ä½¿ç”¨è¡Œç‚ºç‰¹å¾µé€²è¡Œåˆ†ç¾¤ï¼ˆä¸åŒ…å«æ¨™ç±¤ï¼‰
X_cluster = agg_unsupervised[features]

kmeans = KMeans(n_clusters=3, random_state=42)
agg_unsupervised['cluster'] = kmeans.fit_predict(X_cluster)

# æŸ¥çœ‹å„ç¾¤çš„å¹³å‡è¡Œç‚ºç‰¹å¾µ
cluster_summary = agg_unsupervised.groupby('cluster')[features].mean()
print("ğŸ“Š Cluster Average Feature Values:")
print(cluster_summary)

# å¯è¦–åŒ–åˆ†ç¾¤çµæœï¼ˆä¾‹å¦‚ session_count vs activity_span_daysï¼‰
plt.figure(figsize=(8,6))
sns.scatterplot(data=agg_unsupervised, x='session_count', y='activity_span_days',
                hue='cluster', palette='Set2', s=100)
plt.title("KMeans Clustering Visualization")
plt.xlabel("Session Count")
plt.ylabel("Activity Span (days)")
plt.show()